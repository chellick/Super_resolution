{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chellick/Super_resolution/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OFsn3uIwJL8G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOuMc3pdJRVd",
        "outputId": "2a3655ad-e82e-40d7-c6ff-c363c8afee23"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qTVbHA1FFKY",
        "outputId": "8aae83cd-c47a-4f77-e22e-3aa170909652"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nIh6x2GTJyts"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 32, 32, 3).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yR9CEXIk_Jrs"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rZuMxTmibxSy"
      },
      "outputs": [],
      "source": [
        "generator = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(2048, input_shape=(100,)),\n",
        "    tf.keras.layers.Reshape((2, 2, 512)),\n",
        "    tf.keras.layers.Conv2DTranspose(256, (5, 5,), strides=(2), padding='same'),\n",
        "    tf.keras.layers.Conv2DTranspose(128, (5, 5,), strides=(2), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2DTranspose(64, (5, 5,), strides=(2), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2DTranspose(3, (5, 5,), strides=(2), padding='same', activation='tanh'),\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5qknOfmL7zP",
        "outputId": "72ea29a4-14cc-4b5f-bb8c-ee89030b51dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2048)              206848    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 4, 4, 256)         3277056   \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 8, 8, 128)         819328    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 8, 8, 128)         512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 16, 16, 64)        204864    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2D  (None, 32, 32, 3)         4803      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4513667 (17.22 MB)\n",
            "Trainable params: 4513283 (17.22 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_4_mZK0kYS-R"
      },
      "outputs": [],
      "source": [
        "discriminator = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(3, input_shape=[32, 32, 3]),\n",
        "    tf.keras.layers.Conv2D(64, (5, 5), strides=(2), padding='same'),\n",
        "    tf.keras.layers.LeakyReLU(),\n",
        "    tf.keras.layers.Conv2D(128, (5, 5), strides=(2), padding='same'),\n",
        "    tf.keras.layers.LeakyReLU(),\n",
        "    tf.keras.layers.Conv2D(256, (5, 5), strides=(2), padding='same'),\n",
        "    tf.keras.layers.LeakyReLU(),\n",
        "    tf.keras.layers.Conv2D(512, (5, 5), strides=(2), padding='same'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kYuRLCNdbea",
        "outputId": "9f6a68cd-207d-4e90-fdcc-7352b531ed09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 32, 32, 3)         12        \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 16, 16, 64)        4864      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 256)         819456    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 2, 2, 512)         3277312   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4308621 (16.44 MB)\n",
            "Trainable params: 4308621 (16.44 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "euDgLqyukOMp"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWO9btk05AAC"
      },
      "source": [
        "Loss \\ train definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XB0wqRMO5Z3P"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "moENqGT32X2i"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BcPuXW0o6FHU"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhxjp0ce6u4O"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U6goLM6A6uah"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "seed = tf.random.normal([100, 100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HfQyjlot69LQ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([100, 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise)\n",
        "\n",
        "        real_output = discriminator(images)\n",
        "        fake_output = discriminator(generated_images)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpEE7At1-orh",
        "outputId": "690df3c8-ef33-478f-e713-c1561985d281"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\keras\\src\\backend.py:5805: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 1 is 613.5584261417389 sec\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\python\\GitHub\\Super_resolution\\GAN.ipynb Ячейка 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/python/GitHub/Super_resolution/GAN.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/python/GitHub/Super_resolution/GAN.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataset:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/python/GitHub/Super_resolution/GAN.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         train_step(batch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/python/GitHub/Super_resolution/GAN.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mTime for epoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/python/GitHub/Super_resolution/GAN.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m generator\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m/content/models/generator\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
            "File \u001b[1;32mc:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
            "File \u001b[1;32mc:\\python\\GitHub\\Super_resolution\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    for batch in train_dataset:\n",
        "        train_step(batch)\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "generator.save('/content/models/generator')\n",
        "discriminator.save('/content/models/discriminator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ludUrARTAItF",
        "outputId": "cb597aaf-c7c2-4f82-eb0e-e9b46368202a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78bb10428e20>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eObC1SXY2SG1",
        "outputId": "b369f8a6-a69a-418a-9c11-7f1af947daa6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=bool, numpy=array([[ True]])>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "discriminator(generated_image) > 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOxb4FtVRzIuWIFBpNhATYa",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
